# hamilton-2020-managing-financial-risk-tradeoffs-for-hydropower
This repository contains all code and data (included data for figures) for the following paper:

Hamilton, A.L., Characklis, G.W., &amp; Reed, P.M. (2020). Managing financial risk tradeoffs for hydropower generation using snowpack-based index contracts. (in prep).

Licensed under the GNU General Public License v3.0. In building the multi-objective optimization (MOO) component of this code base, I borrowed and built upon sections of Julianne Quinn's [Lake Problem Direct Policy Search code](https://github.com/julianneq/Lake_Problem_DPS).

## Contents
* `code/` - directory with all code used to replicate paper
  * `synthetic_data_and_moea_plots/` - Python and bash scripts needed for (1) Generating all synthetic time series, (2) Plotting related to synthetic data, (3) Plotting related to MOO output
  * `optimization/` - C++ and bash scripts needed for MOO
    * here
    * here
  * `misc/` - directory for storing third-party software
    * `HypervolumeEval.class` - Class for calculating hypervolume with MOEAFramework, written by Dave Hadka, created following instructions [here](https://waterprogramming.wordpress.com/2015/08/26/moea-diagnostics-for-a-simple-test-case-part-23/)
    * `boostutil.h` - Utility functions for boost matrices/vectors, taken from [Lake Problem DPS](https://github.com/julianneq/Lake_Problem_DPS/blob/master/Optimization/boostutil.h) by Julianne Quinn.
* `data/` - directory with all data
  * `downloaded_inputs/` - original data (sources described in manuscript)
    * `ice_electric-*final.xls`, `NP15Hub.xls` - Historical electricity price data at NP15 hub in northern California
    * `SeriesReport-20190311141838_d27dd7.xlsx` - Historical consumer price index data
    * `SFPUC_Combined_Public.xlsx` - Historical hydropower generation and sales for SFPUC
    * `SFPUC_genMonthly.csv` - Historical hydropower generation for SFPUC (after manually aggregating across sources to monthly time step)
    * `swe_dana_meadows.csv` - Historical snow water equivalent depth at Dana Meadows snow station
  * `generated_inputs/` - data generated by user
    * `param_LHC_bounds.txt` - parameter file dictating bounds for Latin Hypercube Sample across parameter space for sensitivity analysis
    * Other files created by model itself, as described below
  * `moea_output/` - outputs from MOO needed for furthur analysis
    * `baseline/` - results from MOO using baseline parameters(SFPUC October 2016 estimates)
    * `sensitivity_analysis/` - results from MOO for sensitivity analysis
* `figures/` - directory for storing figures

## Running the model
### Set-up
* Clone the model and install dependencies. 
  * Synthetic generation and all plotting is set up to run on my Windows laptop, using a linux bash shell (e.g., Cygwin), and Python 3.6.1, plus the Python libraries below. If using a different setup, you may have to make alterations to the bash scripts.
    * Python libraries: numpy, pandas, matplotlib, seaborn, importlib, datetime, statsmodels, math, scipy
  * Optimization set up to run on [THECUBE](https://www.cac.cornell.edu/wiki/index.php?title=THECUBE_Cluster), a cluster housed at Cornell University. THECUBE uses the slurm scheduler. Submission scripts and makefiles may need to be altered to accomodate different setups.
* Additional software
  * Download the [Borg MOEA](http://borgmoea.org/) source code
    * Create a new directory called `borg` within the `code/misc/` directory and place the source code here.
  * Download the "Compiled Binaries" from the [MOEAFramework](http://www.moeaframework.org/) website.
    * Copy the `moeaframework.c` &amp `moeaframework.h` files (from the `MOEAFramework-*/examples` directory of the packag) to `code/misc/borg` 
  * Download the "Demo Application" from the [MOEAFramework](http://www.moeaframework.org/) website.
    * Move `MOEAFramework-*-Demo.jar` to `code/misc'
  * Download `pareto.py` from [Github](https://github.com/matthewjwoodruff/pareto.py) 
    * Move to `code/misc`
* Create Latin Hypercube Sample for sensitivity analysis. 
  * From project home directory, navigate to the code directory for synthetic data generation (`cd code/synthetic_data_and_moea_plots`)
  * Now run LHC sample script (`sh get_sample_LHC.sh`)
  * Output (`data/generated_inputs/param_LHC_sample.txt`) will have five columns (one for each uncertain factor) and 151 rows. The first 150 are from the LHC sample, and the last is the baseline parameter values.
* Create synthetic time series and related plots
  * Run `make_synthetic_data_plots.py`, either in an IDE such as Pycharm, or in a bash shell (`python make_synthetic_data_plots.py` from `code/synthetic_data_and_moea_plots` directory)
    * This takes about 7 minutes on my laptop.
    * Outputs
      * `data/generated_inputs/synthetic_data.txt` - Synthetic time series of SWE, revenue, and CFD contract payouts (using baseline market price of risk (lambda) parameter value). Needed for MOO.
      * `data/generated_inputs/param_LHC_sample_withLamPremShift.txt` - Parameter sample file with a newly-calculated contract for differences (CFD) pricing shift based on sampled market price of risk (lambda) value. Used in sensitivity analysis MOOs.
      * Figures 2-6 from main text and S2-S3 from Supporting Information text
  * Run `make_swe_copula_plot.py` 
    * This function is slow, about ~~~ on my laptop. Skip this step if you don't care about this plot
    * Output - Figure S1 from Supporting Information
* Transfer new files from `data/generated_inputs/` to cluster (skip this step if performing all analysis on same machine)
* Create baseline, sensitivity, & retest versions. Compile each C++ using MPI. 
  * `sh remake.sh`
* Run MOO for baseline & sensitivity analysis, from `code/optimization/` directory, in bash shell.
  * `sbatch run_baseline_borgms.sh`
  * `sbatch run_sensitivity_borgms.sh`
  * Outputs
    * `data/optimization_output/baseline/sets/param150_seedS1_seedB*.set`, for values of * in 1-50
    * `data/optimization_output/baseline/runtime/param150_seedS1_seedB*.runtime`, for values of * in 1-50
    * `data/optimization_output/sensitivity/sets/param@_seedS1_seedB*.set`, for values of * in 1-10, @ in 1-150
    * `data/optimization_output/sensitivity/runtime/param@_seedS1_seedB*.runtime`, for values of * in 1-10, @ in 1-150
